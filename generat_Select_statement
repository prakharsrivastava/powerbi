import org.apache.spark.sql.{DataFrame, Row, SparkSession}

object Main {
  def main(args: Array[String]): Unit = {
    // Create SparkSession
    val spark = SparkSession.builder()
      .appName("ScalaMapExample")
      .master("local[2]")
      .getOrCreate()

    // Sample DataFrame
    val df: DataFrame = spark.createDataFrame(Seq(
      (1, 1, "Y"),
      (2, 2, "Z"),
      (3, 3, "X")
    )).toDF("col1", "col2", "col3")

    // Define the map with string as key and tuple as value
    val myMap: Map[String, (String, String, String)] = Map(
      "key1" -> ("1", "1", "Y"),
      "key2" -> ("2", "2", "Z"),
      "key3" -> ("3", "3", "X")
    )

   // Iterate through DataFrame and check if rows match the map values
    val rowsMatched: Boolean = df.collect().forall {
      case Row(col1: Int, col2: Int, col3: String) =>
        val key = s"$col1$col2$col3"
        myMap.get(key) match {
          case Some((mapCol1, mapCol2, mapCol3)) => col1.toString == mapCol1 && col2.toString == mapCol2 && col3 == mapCol3
          case None => false
        }
    }
