import org.apache.spark.sql.{SparkSession, functions => F}
import org.apache.spark.sql.types._

object DemoCheck extends App {
  // Initialize Spark session
  val spark = SparkSession.builder
    .appName("DemoCheck")
    .master("local[*]")
    .getOrCreate()

  import spark.implicits._

  // Sample data
  val data = Seq(
    ("1110", Array("{\"color\":\"black\"}", "{\"gift\":\"no\"}")),
    ("1111", Array("{\"color\":\"blue\"}", "{\"gift\":\"yes\"}"))
  )

  // Create DataFrame
  val df = data.toDF("raw_stu_id", "demo")

  // Function to cast ArrayType columns to StringType
  def castArrayTypeColumnsToString(df: org.apache.spark.sql.DataFrame): org.apache.spark.sql.DataFrame = {
    df.schema.fields.foldLeft(df) { (tempDf, field) =>
      field.dataType match {
        case ArrayType(_, _) =>
          tempDf.withColumn(field.name, F.col(field.name).cast(StringType))
        case _ =>
          tempDf
      }
    }
  }

  // Apply the function to cast appropriate columns
  val newDf = castArrayTypeColumnsToString(df)

  // Show the DataFrame
  newDf.show(false)
  newDf.printSchema()

  // Stop the Spark session
  spark.stop()
}
