import org.apache.spark.sql.{SparkSession, Row}
import org.apache.spark.sql.types._
import org.apache.spark.sql.functions._

// Sample data as JSON strings
val jsonData = """[{"label": "color", "value": "black"}, {"label": "gift", "value": "no"}]"""

// Create SparkSession
val spark = SparkSession.builder()
  .appName("Parse JSON Array to Columns")
  .master("local[*]")
  .getOrCreate()

import spark.implicits._

// Define schema for the JSON structure
val schema = ArrayType(
  StructType(Seq(
    StructField("label", StringType, nullable = false),
    StructField("value", StringType, nullable = false)
  ))
)

// Create DataFrame from JSON string
val df = spark.read
  .option("multiline", "true")
  .json(Seq(jsonData).toDS)

// Explode the array of structs into separate rows
val explodedDF = df.withColumn("exploded", explode($"value"))

// Select and rename columns
val parsedDF = explodedDF.select(
  $"exploded.label".alias("col"),
  $"exploded.value".alias("value")
)

// Display the parsed DataFrame
parsedDF.show(false)
