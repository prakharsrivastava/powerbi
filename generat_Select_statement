import org.apache.spark.sql.{Column, DataFrame}

// Assuming 'df' is your DataFrame with duplicate column names
val aliasedColumns = df.columns.map(col(_).as(s"${_}_alias"))

// Creating a struct with aliased columns
val structColumn: Column = struct(aliasedColumns: _*)

// Selecting the DataFrame with the new struct column
val resultDF: DataFrame = df.select(structColumn.alias("combined_struct"))

// Show the resulting DataFrame
resultDF.show()
