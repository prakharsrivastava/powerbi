import org.apache.spark.sql.{DataFrame, SparkSession}
import org.apache.spark.sql.functions._

object Main {
  def main(args: Array[String]): Unit = {
    val spark = SparkSession.builder()
      .appName("ColumnSelection")
      .master("local[*]")
      .getOrCreate()

    import spark.implicits._

    val data = Seq(
      (true, true, true),
      (false, true, true),
      (true, true, true)
    )

    val df = data.toDF("col1", "col2", "col3")

    val resultDF = df.withColumn("result", lit(false)) // Initialize result column with false

    val columnNames = df.columns

    val updatedDF = columnNames.foldLeft(resultDF) { (df, columnName) =>
      df.withColumn(columnName, when(col(columnName), lit(columnName)).otherwise(lit(null)))
    }

    val finalDF = updatedDF.withColumn("result", when(col("col1").isNotNull && col("col2").isNotNull && col("col3").isNotNull, lit(true)).otherwise(lit(false)))

    finalDF.select("result", "col1", "col2", "col3").collect().foreach { row =>
      val result = row.getAs[Boolean]("result")
      val trueColumns = row.getValuesMap[Boolean](Seq("col1", "col2", "col3")).filter(_._2).keys.toList
      println(s"$result, $trueColumns")
    }
  }
}
