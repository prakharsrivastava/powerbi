import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._

// Step 1: Create a Spark session
val spark = SparkSession.builder
  .appName("JsonConversion")
  .getOrCreate()

// Step 2: Sample DataFrame
val df = Seq(
  ("[{label:eye Color,value : brown},{label:white Color}]"),
  ("[{label:height,value : 6ft},{label:weight,value : 70kg}]")
).toDF("jsonString")

// Step 3: Define a function to convert the string to JSON format
def convertToJson(jsonStr: String): String = {
  val cleanedStr = jsonStr
    // Match keys and add quotes, handle both quoted and unquoted values
    .replaceAll("\\{(\\s*)(\\w+)\\s*:", "{$1\"$2\":")
    .replaceAll(",(\\s*)(\\w+)\\s*:", ",$1\"$2\":")
    .replaceAll(":\\s*(\\w+)([,\\}])", ": \"$1\"$2")
    .replaceAll(":\\s*(\\w+),", ": \"$1\",") // handle unquoted values without trailing comma
    .replaceAll("\\s*}", "}")
  "[" + cleanedStr + "]"
}

// Step 4: Register the UDF
val convertToJsonUDF = udf(convertToJson _)

// Step 5: Apply the UDF to the DataFrame column
val resultDF = df.withColumn("jsonWithQuotes", convertToJsonUDF($"jsonString"))

// Step 6: Show the result
resultDF.show(false)
