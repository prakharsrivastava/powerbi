import org.apache.spark.sql.types._

// Define a function to revert a specific column from ArrayType to StringType
def revertArrayToString(schema: StructType, columnName: String): StructType = {
  val newFields = schema.fields.map {
    case StructField(name, ArrayType(_, _), nullable, metadata) if name == columnName =>
      StructField(name, StringType, nullable, metadata)
    case StructField(name, struct: StructType, nullable, metadata) =>
      StructField(name, revertArrayToString(struct, columnName), nullable, metadata)
    case other =>
      other
  }
  StructType(newFields)
}

// Example usage:
val originalSchema = StructType(Seq(
  StructField("lastname", StringType, nullable = true),
  StructField("demo", ArrayType(
    StructType(Seq(
      StructField("label", StringType, nullable = true),
      StructField("value", StringType, nullable = true)
    ))
  ), nullable = true)
))

// Convert "demo" column from ArrayType back to StringType
val updatedSchema = revertArrayToString(originalSchema, "demo")

// Print the updated schema
println("Updated Schema:")
updatedSchema.printTreeString()
