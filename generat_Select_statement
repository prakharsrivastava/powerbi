import org.apache.spark.sql.{DataFrame, SparkSession}
import org.apache.spark.sql.functions._

case class Param(attribute: String, value: Seq[String])

def filter(dataframe: DataFrame, param: Option[Seq[Param]]): DataFrame = {
  param match {
    case Some(params) =>
      val filteredDf = params.foldLeft(dataframe) { (df, p) =>
        val attribute = p.attribute
        val values = p.value
        val tempColumn = s"${attribute}_temp"
        if (df.columns.contains(tempColumn)) {
          df.filter(col(tempColumn).isin(values: _*))
        } else {
          df
        }
      }

      val columnsToDrop = filteredDf.columns.filter(_.endsWith("_temp"))
      if (columnsToDrop.nonEmpty) {
        filteredDf.drop(columnsToDrop: _*)
      } else {
        filteredDf
      }

    case None => dataframe
  }
