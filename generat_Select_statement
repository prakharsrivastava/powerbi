import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._

// Step 1: Create a Spark session
val spark = SparkSession.builder
  .appName("JsonConversion")
  .getOrCreate()

// Step 2: Sample DataFrame
val df = Seq(
  ("[{label:eye Color,value : brown},{label:white Color}]"),
  ("[{label:height,value : 6ft},{label:weight,value : 70kg}]")
).toDF("jsonString")

// Step 3: Define a function to split and convert the string to JSON format
def convertToJson(jsonStr: String): String = {
  val parts = jsonStr.split("\\},\\{") // Split by },{ to separate individual JSON objects
  val cleanedStr = parts.map { part =>
    // Match keys and add quotes, handle both quoted and unquoted values
    part
      .replaceAll("\\{\\s*(\\w+)\\s*:", "{\"$1\":")
      .replaceAll(",\\s*(\\w+)\\s*:", ",\"$1\":")
      .replaceAll(":\\s*(\\w+)([,\\}])", ": \"$1\"$2")
      .replaceAll("\\s*}", "}")
  }.mkString("[", ",", "]") // Join parts back together with []

  cleanedStr
}

// Step 4: Register the UDF
val convertToJsonUDF = udf(convertToJson _)

// Step 5: Apply the UDF to the DataFrame column
val resultDF = df.withColumn("jsonWithQuotes", convertToJsonUDF($"jsonString"))

// Step 6: Show the result
resultDF.show(false)
