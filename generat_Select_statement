import org.apache.spark.sql.{SparkSession, DataFrame}
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._

object ConvertStringToArrayType extends App {
  // Initialize SparkSession
  val spark = SparkSession.builder
    .appName("Convert StringType to ArrayType")
    .master("local[*]")
    .getOrCreate()

  import spark.implicits._

  // Example DataFrame with a StringType column containing CSV format
  val data = Seq(
    ("Smith", "color:black, gift:no"),
    ("Johnson", "color:white, gift:yes")
  ).toDF("lastname", "demo")

  // Define the schema for the array elements
  val targetArraySchema = new StructType()
    .add("key", StringType)
    .add("value", StringType)

  // Function to parse CSV string and convert it to array of structs
  val parseCsvToArray = udf((csv: String) => {
    csv.split(", ").map { pair =>
      val Array(key, value) = pair.split(":")
      Row(key, value)
    }
  }, ArrayType(targetArraySchema))

  // Apply the UDF to convert the StringType column to ArrayType
  val newDf = data.withColumn("demo", parseCsvToArray(col("demo")))

  // Show the transformed DataFrame
  newDf.show(false)

  // Print the schema of the new DataFrame
  newDf.printSchema()
}
