import org.apache.spark.sql.{SparkSession, Row}
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._

// Create SparkSession
val spark = SparkSession.builder()
  .appName("Convert Array to JSON")
  .master("local[*]")
  .getOrCreate()

import spark.implicits._

// Sample data
val data = Seq(
  ("suszan kapoor", Seq(("color", "black"), ("gift", "no")))
).toDF("lastname", "demo")

// Define the schema for the demo column
val demoSchema = ArrayType(StructType(Seq(
  StructField("label", StringType, true),
  StructField("value", StringType, true)
)))

// Define UDF to convert Seq[(String, String)] to JSON array string
val convertToJSONString = udf((demo: Seq[Row]) => {
  demo.map { case Row(label: String, value: String) =>
    s"""{"label":"$label","value":"$value"}"""
  }.mkString("[", ",", "]")
}, StringType)

// Apply the UDF to transform the demo column
val transformedDF = data.withColumn("demo", convertToJSONString($"demo"))

// Show the transformed DataFrame
transformedDF.show(false)
