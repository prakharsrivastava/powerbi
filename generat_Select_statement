import org.apache.spark.sql.{SparkSession, Row}
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._

// Create SparkSession
val spark = SparkSession.builder()
  .appName("Convert Array to JSON")
  .master("local[*]")
  .getOrCreate()

import spark.implicits._

// Sample data
val data = Seq(
  ("suszan kapoor", Seq(Row("color", "black"), Row("gift", "no")))
).toDF("lastname", "demo")

// Define the schema for the demo column
val demoSchema = ArrayType(StructType(Seq(
  StructField("label", StringType, true),
  StructField("value", StringType, true)
)))

// Convert the demo column to JSON string
val transformedDF = data.withColumn("demo", to_json($"demo", Map("pretty" -> "false")))

// Show the transformed DataFrame
transformedDF.show(false)

// Parse the JSON string back to an array of structs
val parsedDF = transformedDF.withColumn("demo", from_json($"demo", demoSchema))

// Show the parsed DataFrame
parsedDF.show(false)

// Explode the array of structs into separate rows
val explodedDF = parsedDF.withColumn("demo", explode($"demo"))

// Pivot the exploded rows into columns
val pivotedDF = explodedDF.select($"lastname", $"demo.*").groupBy($"lastname").pivot("label").agg(first("value"))

// Show the final DataFrame
pivotedDF.show(false)
