import org.apache.spark.sql.types._

object ConvertArrayType extends App {
  // Define the original schema
  val originalSchema = StructType(Seq(
    StructField("lastname", StringType),
    StructField("demo", ArrayType(StructType(Seq(
      StructField("label", StringType),
      StructField("value", StringType)
    ))))
  ))

  // Function to convert ArrayType to StringType in a schema
  def convertArrayType(schema: DataType): DataType = {
    schema match {
      case StructType(fields) => 
        StructType(fields.map {
          case StructField(name, ArrayType(_, _), nullable, metadata) => 
            StructField(name, StringType, nullable, metadata)
          case StructField(name, fieldType, nullable, metadata) => 
            StructField(name, convertArrayType(fieldType), nullable, metadata)
        })
      case other => other
    }
  }

  // Convert the schema
  val newSchema = convertArrayType(originalSchema).asInstanceOf[StructType]

  // Print the original and new schema
  println("Original Schema:")
  println(originalSchema.prettyJson)

  println("New Schema:")
  println(newSchema.prettyJson)
}
