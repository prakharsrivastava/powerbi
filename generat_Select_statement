import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._

// Create SparkSession
val spark = SparkSession.builder()
  .appName("Parse JSON Array in String")
  .master("local[*]")
  .getOrCreate()

import spark.implicits._

// Sample data
val data = Seq(
  ("suszan kapoor", """[{"label":"color","value":"black"},{"label":"gift","value":"no"}]"""),
  ("john doe", """[{"label":"color","value":"blue"},{"label":"gift","value":"yes"}]""")
).toDF("lastname", "demo")

// Define schema for the JSON data
val demoSchema = ArrayType(StructType(Seq(
  StructField("label", StringType, true),
  StructField("value", StringType, true)
)))

// Convert JSON string to array of structs
val parsedDF = data.withColumn("demo", from_json($"demo", demoSchema))

// Explode the array into separate rows
val explodedDF = parsedDF.withColumn("exploded", explode($"demo"))

// Pivot the DataFrame to get key-value pairs as separate columns
val pivotedDF = explodedDF
  .select($"lastname", $"exploded.label", $"exploded.value")
  .groupBy($"lastname")
  .pivot($"label")
  .agg(first($"value"))

// Display the transformed DataFrame
pivotedDF.show(false)
