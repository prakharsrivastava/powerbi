import org.apache.spark.sql.{SparkSession, functions => F}
import org.apache.spark.sql.types._

object DemoCheck extends App {
  // Initialize Spark session
  val spark = SparkSession.builder
    .appName("DemoCheck")
    .master("local[*]")
    .getOrCreate()

  import spark.implicits._

  // Sample data
  val data = Seq(
    ("1110", Array("{\"color\":\"black\"}", "{\"gift\":\"no\"}")),
    ("1111", Array("{\"color\":\"blue\"}", "{\"gift\":\"yes\"}"))
  )

  // Create DataFrame
  val df = data.toDF("raw_stu_id", "demo")

  // Identify ArrayType columns
  val arrayTypeColumns = df.schema.fields.collect {
    case field if field.dataType.isInstanceOf[ArrayType] => field.name
  }

  // Cast ArrayType columns to StringType
  var newDf = df
  for (columnName <- arrayTypeColumns) {
    newDf = newDf.withColumn(columnName, F.col(columnName).cast(StringType))
  }

  // Show the DataFrame
  newDf.show(false)
  newDf.printSchema()

  // Stop the Spark session
  spark.stop()
}
