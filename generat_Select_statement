import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.types._

object ConvertStringToArrayType extends App {
  // Initialize SparkSession
  val spark = SparkSession.builder
    .appName("Convert String to ArrayType")
    .master("local[*]")
    .getOrCreate()

  import spark.implicits._

  // Example DataFrame with a string column containing JSON-like data
  val data = Seq(
    ("Smith", """[{"label":"EYEcolor","value":"blue"},{"label":"gifterd","value":null}]"""),
    ("Johnson", """[{"label":"EYEcolor","value":"green"},{"label":"gifterd","value":"yes"}]""")
  ).toDF("lastname", "demo")

  // Print the original schema
  println("Original Schema:")
  data.printSchema()

  // Define the target schema for the JSON string
  val targetSchema = ArrayType(StructType(Seq(
    StructField("label", StringType, nullable = true),
    StructField("value", StringType, nullable = true)
  )))

  // Apply schema transformation to parse the string column into ArrayType of StructType
  val updatedDF = data.withColumn("demo_parsed", from_json($"demo", targetSchema))

  // Print the updated schema
  println("\nUpdated Schema:")
  updatedDF.printSchema()

  // Show the transformed DataFrame
  updatedDF.show(false)
}
