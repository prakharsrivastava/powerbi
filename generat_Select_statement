import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._

// Assuming df is your DataFrame with a column named startTime
val df = // ...

// Define the new schema with a single struct column
val newSchema = StructType(Seq(
  StructField("startTime", DataTypes.createStructType(Array(
    StructField("_1", DataTypes.TimestampType, nullable = true),
    StructField("_2", DataTypes.LongType, nullable = true)
  )), nullable = true),
  StructField("academicYearOffset_part", StringType),
  StructField("subject_part", StringType)
))

// Convert the startTime column to the correct structure and cast it to the case class
val updatedDf = df.withColumn(
  "startTime",
  struct(
    col("startTime").cast(TimestampType).alias("_1"),
    lit(null).cast(LongType).alias("_2")
  ).cast(newSchema("startTime"))
)

// Show the updated DataFrame
updatedDf.show()
