import org.apache.spark.sql.{SparkSession, DataFrame}
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._

object ExportDataFrameToCSV extends App {
  // Initialize SparkSession
  val spark = SparkSession.builder
    .appName("Export DataFrame to CSV")
    .master("local[*]")
    .getOrCreate()

  import spark.implicits._

  // Example data
  val data = Seq(
    ("suzan kapoor", Seq(("color", "black"), ("gift", "no"))),
    ("john doe", Seq(("color", "blue"), ("gift", "yes")))
  )

  // Define the schema
  val schema = StructType(Seq(
    StructField("lastname", StringType, true),
    StructField("state_demo", ArrayType(StructType(Seq(
      StructField("label", StringType, true),
      StructField("value", StringType, true)
    ))), true)
  ))

  // Create DataFrame
  val df = spark.createDataFrame(data).toDF("lastname", "state_demo")

  // Flatten the state_demo array column into a JSON string
  val flattenedDF = df.withColumn("state_demo_json", to_json($"state_demo"))
    .drop("state_demo")

  // Define the path to save CSV file
  val csvPath = "/path/to/save/file.csv"

  // Write DataFrame to CSV
  flattenedDF.coalesce(1)  // coalesce to 1 partition for single output file
    .write
    .option("header", "true")
    .csv(csvPath)

  // Stop SparkSession
  spark.stop()
}
