  val df: DataFrame = spark.createDataFrame(Seq(
      ("ginny", "1", "2019-09-15T00:00:00.000Z", "2019-12-15T00:00:00.000Z", "Y", "Y", "N", "N", "N", "N", "male", "White", "MALE", "WHITE", "year2020-2021", "1", "1", "hogwarts", "gryffindor", "English")
    )).toDF("raw_student_id", "Student_Grade", "Completion_Date", "next_completion_date", "Diagnostic_used_to_establish_Growth_Measures_YN", "Economically_Disadvantaged", "English_Language_Learner", "Hispanic_or_Latino", "Migrant", "Special_Education", "Gender", "Race", "GenderEnum", "RaceEnum", "Academic_Year", "Lesson_Grade", "Lesson_Level", "externalAccountId", "school_id", "Diagnostic_Language")

    // Convert DataFrame to Map[String, (String, String, String)]
    val expectedData: Map[String, (String, String, String)] = df.collect().map { row =>
      val raw_student_id = row.getString(0)
      val student_grade = row.getString(1)
      val completion_date = row.getString(2)
      val diagnostic_used = row.getString(4)
      raw_student_id -> (student_grade, completion_date, diagnostic_used)
    }.toMap
