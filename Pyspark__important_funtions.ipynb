{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMoK6zMJ2vfferob7A+cD8J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prakharsrivastava/powerbi/blob/main/Pyspark__important_funtions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "IpYZ3cRGEMKi",
        "outputId": "b63ecf14-1218-44e6-dd11-1fb032928588",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive/chapter2\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/MyDrive/chapter2/\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install findspark \n",
        "!pip install  pyspark\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCrzFNAWxB9w",
        "outputId": "0ef22a71-4ba5-4186-f770-91a3d22267cc"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: findspark in /usr/local/lib/python3.8/dist-packages (2.0.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.8/dist-packages (3.3.2)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.8/dist-packages (from pyspark) (0.10.9.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "spark = SparkSession.builder.master(\"local[1]\").appName(\"architectinaction.com\").getOrCreate()\n",
        "sc= spark.sparkContext"
      ],
      "metadata": {
        "id": "2GRvpurTxEOc"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize([1,2,3,4,5,6,7,8,9,10])"
      ],
      "metadata": {
        "id": "LKPbBIrOxIct"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rddCollect = rdd.collect()\n",
        "print(\"Number of Partitions: \"+str(rdd.getNumPartitions()))\n",
        "print(\"Action: First element: \"+str(rdd.first()))\n",
        "print(rddCollect)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04bipVVpxk5J",
        "outputId": "b251f2cf-4422-4bfb-d53f-e98d7b42a315"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Partitions: 1\n",
            "Action: First element: 1\n",
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "emptyRDD = sc.emptyRDD()\n",
        "emptyRDD2 = rdd=sc.parallelize([])\n",
        "\n",
        "print(\"is Empty RDD : \"+str(emptyRDD2.isEmpty()))"
      ],
      "metadata": {
        "id": "3qZ5uhzsxr_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create spark session with local[5]\n",
        "rdd = sc.parallelize(range(0,20))\n",
        "print(\"From local[5] : \"+str(rdd.getNumPartitions()))\n",
        "\n",
        "# Use parallelize with 6 partitions\n",
        "rdd1 = sc.parallelize(range(0,25), 6)\n",
        "print(\"parallelize : \"+str(rdd1.getNumPartitions()))\n",
        "\n",
        "rddFromFile = sc.textFile(\"readme.html\",10)\n",
        "print(\"TextFile : \"+str(rddFromFile.getNumPartitions()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvJDACuSx10c",
        "outputId": "d7e9b31a-267e-4cac-b2f7-43c3274ae50c"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From local[5] : 1\n",
            "parallelize : 6\n",
            "TextFile : 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rddFromFile.saveAsTextFile(\"partition2\")\n"
      ],
      "metadata": {
        "id": "VF-00855zSC_"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using repartition\n",
        "rdd2 = rddFromFile.repartition(4)\n",
        "print(\"Repartition size : \"+str(rdd2.getNumPartitions()))\n",
        "rdd2.saveAsTextFile(\"re-partition_\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ra_nVqXpzoUb",
        "outputId": "017b08f9-0414-46dd-af1f-823393c4afcb"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repartition size : 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using coalesce()\n",
        "rdd3 = rdd1.coalesce(4)\n",
        "print(\"Repartition size : \"+str(rdd3.getNumPartitions()))\n",
        "rdd3.saveAsTextFile(\"coalesce_\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3qMaqCUz2x4",
        "outputId": "bc66f1d4-97bd-4c83-d7c4-3e4216a176d0"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repartition size : 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql.types import StructType,StructField, StringType, IntegerType,ArrayType,MapType\n",
        "from pyspark.sql.functions import col,struct,when\n",
        "\n",
        "data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
        "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
        "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
        "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
        "    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n",
        "  ]\n",
        "\n",
        "spark.createDataFrame(data).show(truncate=False)\n",
        "schema = StructType([ \n",
        "    StructField(\"firstname\",StringType(),True), \n",
        "    StructField(\"middlename\",StringType(),True), \n",
        "    StructField(\"lastname\",StringType(),True), \n",
        "    StructField(\"id\", StringType(), True), \n",
        "    StructField(\"gender\", StringType(), True), \n",
        "    StructField(\"salary\", IntegerType(), True) \n",
        "  ])\n",
        " \n",
        "df = spark.createDataFrame(data=data,schema=schema)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNmSP8fD1p5R",
        "outputId": "9659f5a5-995d-41c4-abe2-85ba5ad9315f"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+--------+-----+---+----+\n",
            "|_1     |_2  |_3      |_4   |_5 |_6  |\n",
            "+-------+----+--------+-----+---+----+\n",
            "|James  |    |Smith   |36636|M  |3000|\n",
            "|Michael|Rose|        |40288|M  |4000|\n",
            "|Robert |    |Williams|42114|M  |4000|\n",
            "|Maria  |Anne|Jones   |39192|F  |4000|\n",
            "|Jen    |Mary|Brown   |     |F  |-1  |\n",
            "+-------+----+--------+-----+---+----+\n",
            "\n",
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: integer (nullable = true)\n",
            "\n",
            "+---------+----------+--------+-----+------+------+\n",
            "|firstname|middlename|lastname|id   |gender|salary|\n",
            "+---------+----------+--------+-----+------+------+\n",
            "|James    |          |Smith   |36636|M     |3000  |\n",
            "|Michael  |Rose      |        |40288|M     |4000  |\n",
            "|Robert   |          |Williams|42114|M     |4000  |\n",
            "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
            "|Jen      |Mary      |Brown   |     |F     |-1    |\n",
            "+---------+----------+--------+-----+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "structureData = [\n",
        "    ((\"James\",\"\",\"Smith\"),\"36636\",\"M\",3100),\n",
        "    ((\"Michael\",\"Rose\",\"\"),\"40288\",\"M\",4300),\n",
        "    ((\"Robert\",\"\",\"Williams\"),\"42114\",\"M\",1400),\n",
        "    ((\"Maria\",\"Anne\",\"Jones\"),\"39192\",\"F\",5500),\n",
        "    ((\"Jen\",\"Mary\",\"Brown\"),\"\",\"F\",-1)\n",
        "  ]\n",
        "\n",
        "spark.createDataFrame(structureData).show(truncate=False)\n",
        "structureSchema = StructType([\n",
        "        StructField('name', StructType([\n",
        "             StructField('firstname', StringType(), True),\n",
        "             StructField('middlename', StringType(), True),\n",
        "             StructField('lastname', StringType(), True)\n",
        "             ])),\n",
        "         StructField('id', StringType(), True),\n",
        "         StructField('gender', StringType(), True),\n",
        "         StructField('salary', IntegerType(), True)\n",
        "         ])\n",
        "\n",
        "df2 = spark.createDataFrame(data=structureData,schema=structureSchema)\n",
        "df2.printSchema()\n",
        "df2.show(truncate=False)\n",
        "\n",
        "\n",
        "updatedDF = df2.withColumn(\"OtherInfo\", \n",
        "    struct(col(\"id\").alias(\"identifier\"),\n",
        "    col(\"gender\").alias(\"gender\"),\n",
        "    col(\"salary\").alias(\"salary\"),\n",
        "    when(col(\"salary\").cast(IntegerType()) < 2000,\"Low\")\n",
        "      .when(col(\"salary\").cast(IntegerType()) < 4000,\"Medium\")\n",
        "      .otherwise(\"High\").alias(\"Salary_Grade\")\n",
        "  ))\n",
        "#.drop(\"id\",\"gender\",\"salary\")\n",
        "\n",
        "updatedDF.printSchema()\n",
        "updatedDF.show(truncate=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKOd-eeM1zRY",
        "outputId": "c72f7ffd-45db-4d5e-9a76-357817632360"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+---+----+\n",
            "|_1                  |_2   |_3 |_4  |\n",
            "+--------------------+-----+---+----+\n",
            "|{James, , Smith}    |36636|M  |3100|\n",
            "|{Michael, Rose, }   |40288|M  |4300|\n",
            "|{Robert, , Williams}|42114|M  |1400|\n",
            "|{Maria, Anne, Jones}|39192|F  |5500|\n",
            "|{Jen, Mary, Brown}  |     |F  |-1  |\n",
            "+--------------------+-----+---+----+\n",
            "\n",
            "root\n",
            " |-- name: struct (nullable = true)\n",
            " |    |-- firstname: string (nullable = true)\n",
            " |    |-- middlename: string (nullable = true)\n",
            " |    |-- lastname: string (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: integer (nullable = true)\n",
            "\n",
            "+--------------------+-----+------+------+\n",
            "|name                |id   |gender|salary|\n",
            "+--------------------+-----+------+------+\n",
            "|{James, , Smith}    |36636|M     |3100  |\n",
            "|{Michael, Rose, }   |40288|M     |4300  |\n",
            "|{Robert, , Williams}|42114|M     |1400  |\n",
            "|{Maria, Anne, Jones}|39192|F     |5500  |\n",
            "|{Jen, Mary, Brown}  |     |F     |-1    |\n",
            "+--------------------+-----+------+------+\n",
            "\n",
            "root\n",
            " |-- name: struct (nullable = true)\n",
            " |    |-- firstname: string (nullable = true)\n",
            " |    |-- middlename: string (nullable = true)\n",
            " |    |-- lastname: string (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: integer (nullable = true)\n",
            " |-- OtherInfo: struct (nullable = false)\n",
            " |    |-- identifier: string (nullable = true)\n",
            " |    |-- gender: string (nullable = true)\n",
            " |    |-- salary: integer (nullable = true)\n",
            " |    |-- Salary_Grade: string (nullable = false)\n",
            "\n",
            "+--------------------+-----+------+------+------------------------+\n",
            "|name                |id   |gender|salary|OtherInfo               |\n",
            "+--------------------+-----+------+------+------------------------+\n",
            "|{James, , Smith}    |36636|M     |3100  |{36636, M, 3100, Medium}|\n",
            "|{Michael, Rose, }   |40288|M     |4300  |{40288, M, 4300, High}  |\n",
            "|{Robert, , Williams}|42114|M     |1400  |{42114, M, 1400, Low}   |\n",
            "|{Maria, Anne, Jones}|39192|F     |5500  |{39192, F, 5500, High}  |\n",
            "|{Jen, Mary, Brown}  |     |F     |-1    |{, F, -1, Low}          |\n",
            "+--------------------+-----+------+------+------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Broadcast variables are read-only shared variables that are cached and available on all nodes in a cluster "
      ],
      "metadata": {
        "id": "reohFs1G2f6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drivr\n",
        "states = {\"NY\":\"New York\", \"CA\":\"California\", \"FL\":\"Florida\"}\n",
        "broadcastStates = sc.broadcast(states)\n",
        "\n",
        "#executors\n",
        "states = {\"NY\":\"New York\", \"CA\":\"California\", \"FL\":\"Florida\"}\n",
        "data = [(\"James\",\"Smith\",\"USA\",\"CA\"),\n",
        "    (\"Michael\",\"Rose\",\"USA\",\"NY\"),\n",
        "    (\"Robert\",\"Williams\",\"USA\",\"CA\"),\n",
        "    (\"Maria\",\"Jones\",\"USA\",\"FL\")\n",
        "  ]\n",
        "\n",
        "rdd = sc.parallelize(data)\n",
        "df=spark.createDataFrame(rdd)\n",
        "def state_convert(code):\n",
        "    return broadcastStates.value[code]\n",
        "\n",
        "result = rdd.map(lambda x: (x[0],x[1],x[2],state_convert(x[3]))).collect()\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeZiYzvpk0j-",
        "outputId": "845dd482-58a1-42c8-f853-8f7406240de5"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('James', 'Smith', 'USA', 'California'), ('Michael', 'Rose', 'USA', 'New York'), ('Robert', 'Williams', 'USA', 'California'), ('Maria', 'Jones', 'USA', 'Florida')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "6t2iNDFQlkks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filteDf= rdd.where((rdd['state'].isin(broadcastStates.value)))\n"
      ],
      "metadata": {
        "id": "1WTBwG98lMDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql.functions import lit\n",
        "\n",
        "df=df.withColumn(\"name\",lit(\"architectInAction\"))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV-dFyWMnSYW",
        "outputId": "6a1c9d16-6f31-4dc1-9411-58935162bf18"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+---+---+-----------------+\n",
            "|     _1|      _2| _3| _4|             name|\n",
            "+-------+--------+---+---+-----------------+\n",
            "|  James|   Smith|USA| CA|architectInAction|\n",
            "|Michael|    Rose|USA| NY|architectInAction|\n",
            "| Robert|Williams|USA| CA|architectInAction|\n",
            "|  Maria|   Jones|USA| FL|architectInAction|\n",
            "+-------+--------+---+---+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.reshape.api import concat\n",
        "df=df.withColumn(\"name2\",lit(\"name\"))\n",
        "df.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "VkHlFbZooCcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import concat,col\n",
        "data = [('James','','Smith','1991-04-01','M',3000),\n",
        "  ('Michael','Rose','','2000-05-19','M',4000),\n",
        "  ('Robert','','Williams','1978-09-05','M',4000),\n",
        "  ('Maria','Anne','Jones','1967-12-01','F',4000),\n",
        "  ('Jen','Mary','Brown','1980-02-17','F',-1)\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(data)\n",
        "df2=df.withColumn(\"name3\",concat(col(\"_1\"),lit(\"777\")))\n",
        "             \n",
        "df2.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrrSqkdxqQd-",
        "outputId": "c18dcd10-00a5-48de-9285-602ab84e2400"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+--------+----------+---+----+----------+\n",
            "|_1     |_2  |_3      |_4        |_5 |_6  |name3     |\n",
            "+-------+----+--------+----------+---+----+----------+\n",
            "|James  |    |Smith   |1991-04-01|M  |3000|James777  |\n",
            "|Michael|Rose|        |2000-05-19|M  |4000|Michael777|\n",
            "|Robert |    |Williams|1978-09-05|M  |4000|Robert777 |\n",
            "|Maria  |Anne|Jones   |1967-12-01|F  |4000|Maria777  |\n",
            "|Jen    |Mary|Brown   |1980-02-17|F  |-1  |Jen777    |\n",
            "+-------+----+--------+----------+---+----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"name\").show()\n",
        "df.select(df.name).show()\n",
        "df.select(df[\"name\"]).show()\n",
        "\n",
        "#By using col() function\n",
        "from pyspark.sql.functions import col\n",
        "df.select(col(\"name\")).show()\n",
        "\n",
        "#Select columns by regular expression\n",
        "df.select(df.colRegex(\"`^.*name*`\")).show()"
      ],
      "metadata": {
        "id": "MhWs126PnqOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.distinct().show()\n",
        "df.select(\"_6\").distinct().show()\n",
        "df.dropDuplicates().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4d-0FwP2jxC",
        "outputId": "13505675-d1b7-4b09-cc2a-d3a695086bae"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+--------+----------+---+----+\n",
            "|     _1|  _2|      _3|        _4| _5|  _6|\n",
            "+-------+----+--------+----------+---+----+\n",
            "|    Jen|Mary|   Brown|1980-02-17|  F|  -1|\n",
            "|  James|    |   Smith|1991-04-01|  M|3000|\n",
            "| Robert|    |Williams|1978-09-05|  M|4000|\n",
            "|Michael|Rose|        |2000-05-19|  M|4000|\n",
            "|  Maria|Anne|   Jones|1967-12-01|  F|4000|\n",
            "+-------+----+--------+----------+---+----+\n",
            "\n",
            "+----+\n",
            "|  _6|\n",
            "+----+\n",
            "|4000|\n",
            "|3000|\n",
            "|  -1|\n",
            "+----+\n",
            "\n",
            "+-------+----+--------+----------+---+----+\n",
            "|     _1|  _2|      _3|        _4| _5|  _6|\n",
            "+-------+----+--------+----------+---+----+\n",
            "|    Jen|Mary|   Brown|1980-02-17|  F|  -1|\n",
            "|  James|    |   Smith|1991-04-01|  M|3000|\n",
            "| Robert|    |Williams|1978-09-05|  M|4000|\n",
            "|Michael|Rose|        |2000-05-19|  M|4000|\n",
            "|  Maria|Anne|   Jones|1967-12-01|  F|4000|\n",
            "+-------+----+--------+----------+---+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.distinct().show()\n",
        "print(df.select(\"_6\").distinct().count())\n",
        "df.dropDuplicates().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePjUmIsaFQfn",
        "outputId": "05c4979e-433c-4dd1-8c3f-0e60867d0cc6"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+--------+----------+---+----+\n",
            "|     _1|  _2|      _3|        _4| _5|  _6|\n",
            "+-------+----+--------+----------+---+----+\n",
            "|    Jen|Mary|   Brown|1980-02-17|  F|  -1|\n",
            "|  James|    |   Smith|1991-04-01|  M|3000|\n",
            "| Robert|    |Williams|1978-09-05|  M|4000|\n",
            "|Michael|Rose|        |2000-05-19|  M|4000|\n",
            "|  Maria|Anne|   Jones|1967-12-01|  F|4000|\n",
            "+-------+----+--------+----------+---+----+\n",
            "\n",
            "3\n",
            "+-------+----+--------+----------+---+----+\n",
            "|     _1|  _2|      _3|        _4| _5|  _6|\n",
            "+-------+----+--------+----------+---+----+\n",
            "|    Jen|Mary|   Brown|1980-02-17|  F|  -1|\n",
            "|  James|    |   Smith|1991-04-01|  M|3000|\n",
            "| Robert|    |Williams|1978-09-05|  M|4000|\n",
            "|Michael|Rose|        |2000-05-19|  M|4000|\n",
            "|  Maria|Anne|   Jones|1967-12-01|  F|4000|\n",
            "+-------+----+--------+----------+---+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.select(countDistinct(\"_2\", \"_6\"))\n",
        "df.show()"
      ],
      "metadata": {
        "id": "0EMVF8HkF3xP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#group by\n",
        "#agg() – Using groupBy() agg() function, we can calculate more than one aggregate at a time."
      ],
      "metadata": {
        "id": "h0uVA2T23NPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"_5\").sum(\"_6\").show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2BZcup33UAw",
        "outputId": "25a9bfa5-4c51-435d-ff3a-96db632d6f6c"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+\n",
            "|_5 |sum(_6)|\n",
            "+---+-------+\n",
            "|F  |3999   |\n",
            "|M  |11000  |\n",
            "+---+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"_5\").min(\"_6\").show()"
      ],
      "metadata": {
        "id": "qiNW9AwU3iXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"_5\") .agg(sum(\"_6\").alias(\"sum_salary\"),avg(\"_6\").alias(\"avg_salary\") ).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-NXf7bk31L5",
        "outputId": "529bc4f7-57f9-4136-913f-651a9c82ed86"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+------------------+\n",
            "|_5 |sum_salary|avg_salary        |\n",
            "+---+----------+------------------+\n",
            "|F  |3999      |1999.5            |\n",
            "|M  |11000     |3666.6666666666665|\n",
            "+---+----------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"_5\") .agg(sum(\"_6\").alias(\"sum_salary\"),avg(\"_6\").alias(\"avg_salary\") ).where(col(\"avg_salary\") >= 3000).show(truncate=False)"
      ],
      "metadata": {
        "id": "_6rYfFsC4G_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.join(df,df._5 ==  df._5,\"inner\") \\\n",
        "     .show(truncate=False)"
      ],
      "metadata": {
        "id": "H0VwZU1R4bSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.union(df)\n",
        "df.show()"
      ],
      "metadata": {
        "id": "I95QUkoR4m1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"Seqno\",\"Name\"]\n",
        "data = [(\"1\", \"john jones\"),\n",
        "    (\"2\", \"tracey smith\"),\n",
        "    (\"3\", \"amy sanders\")]\n",
        "\n",
        "df = spark.createDataFrame(data=data,schema=columns)\n",
        "def upperCase(str):\n",
        "    return str.upper()\n",
        "\n",
        "upperCaseUDF = udf(lambda z:upperCase(z),StringType())    \n",
        "\n",
        "df.withColumn(\"Cureated Name\", upperCaseUDF(col(\"Name\"))) \\\n",
        ".show(truncate=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "Xh2XJeOF4yku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.pandas as ps\n",
        "import numpy as np\n",
        "\n",
        "# Create a DataFrame\n",
        "psdf = ps.DataFrame(df)\n",
        "psdf\n"
      ],
      "metadata": {
        "id": "Gb9mGEZL8Sfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def add(data):\n",
        "   return data[0] + \"ffff\"\n",
        "   \n",
        "psdf = psdf.apply(add,axis=1)\n",
        "psdf.head()"
      ],
      "metadata": {
        "id": "4IXayKaB8d-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simpleData = ((\"Java\",4000,5), \\\n",
        "    (\"Python\", 4600,10),  \\\n",
        "    (\"Scala\", 4100,15),   \\\n",
        "    (\"Scala\", 4500,15),   \\\n",
        "    (\"PHP\", 3000,20),  \\\n",
        "  )\n",
        "columns= [\"CourseName\", \"fee\", \"discount\"]\n",
        "\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(data = simpleData, schema = columns)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)\n",
        "\n",
        "# Custom transformation 1\n",
        "from pyspark.sql.functions import upper\n",
        "def to_upper_str_columns(df):\n",
        "    return df.withColumn(\"CourseName\",upper(df.CourseName))\n",
        "\n",
        "# Custom transformation 2\n",
        "def reduce_price(df,reduceBy):\n",
        "    return df.withColumn(\"new_fee\",df.fee - reduceBy)\n",
        "\n",
        "# Custom transformation 3\n",
        "def apply_discount(df):\n",
        "    return df.withColumn(\"discounted_fee\",  \\\n",
        "             df.new_fee - (df.new_fee * df.discount) / 100)\n",
        "\n",
        "# transform() usage\n",
        "df2 = df.transform(to_upper_str_columns) \\\n",
        "        .transform(reduce_price,1000) \\\n",
        "        .transform(apply_discount) \n",
        "                \n",
        "df2.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDukU_k5BLas",
        "outputId": "039b5bc0-a9da-4348-9293-f43c8729c7af"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- CourseName: string (nullable = true)\n",
            " |-- fee: long (nullable = true)\n",
            " |-- discount: long (nullable = true)\n",
            "\n",
            "+----------+----+--------+\n",
            "|CourseName|fee |discount|\n",
            "+----------+----+--------+\n",
            "|Java      |4000|5       |\n",
            "|Python    |4600|10      |\n",
            "|Scala     |4100|15      |\n",
            "|Scala     |4500|15      |\n",
            "|PHP       |3000|20      |\n",
            "+----------+----+--------+\n",
            "\n",
            "+----------+----+--------+-------+--------------+\n",
            "|CourseName| fee|discount|new_fee|discounted_fee|\n",
            "+----------+----+--------+-------+--------------+\n",
            "|      JAVA|4000|       5|   3000|        2850.0|\n",
            "|    PYTHON|4600|      10|   3600|        3240.0|\n",
            "|     SCALA|4100|      15|   3100|        2635.0|\n",
            "|     SCALA|4500|      15|   3500|        2975.0|\n",
            "|       PHP|3000|      20|   2000|        1600.0|\n",
            "+----------+----+--------+-------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = [\"Project Gutenberg’s\",\n",
        "        \"Alice’s Adventures in Wonderland\",\n",
        "        \"Project Gutenberg’s\",\n",
        "        \"Adventures in Wonderland\",\n",
        "        \"Project Gutenberg’s\"]\n",
        "rdd=spark.sparkContext.parallelize(data)\n",
        "rdd.collect()\n"
      ],
      "metadata": {
        "id": "wNFjFEXWB4eG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd2=rdd.flatMap(lambda x: x.split(\" \"))\n",
        "rdd2.collect()\n",
        " "
      ],
      "metadata": {
        "id": "8xvVF_P1CAPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.show()"
      ],
      "metadata": {
        "id": "7pJpxR2SDZdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#overwrite\n",
        "df2.write.mode('append').option(\"header\",True) \\\n",
        "        .option(\"maxRecordsPerFile\", 5) \\\n",
        "        .partitionBy(\"fee\") \\\n",
        "        .mode(\"overwrite\") \\\n",
        "        .csv(\"course\")"
      ],
      "metadata": {
        "id": "5V2DkeebDIqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqUV25UCTpq_",
        "outputId": "8c658f15-9707-41d9-816c-76459a7d9605"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[CourseName: string, fee: bigint, discount: bigint, new_fee: bigint, discounted_fee: double]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"James\",\"M\",60000),(\"Michael\",\"M\",70000),\n",
        "        (\"Robert\",None,400000),(\"Maria\",\"F\",500000),\n",
        "        (\"Jen\",\"\",None)]\n",
        "columns = [\"name\",\"gender\",\"salary\"]\n",
        "df = spark.createDataFrame(data = data, schema = columns)\n",
        "df.show()"
      ],
      "metadata": {
        "id": "UiueTLRyH1Xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn(\"new_gender\", when(df.gender == \"M\",\"Male\")\n",
        "                                 .when(df.gender == \"F\",\"Female\")\n",
        "                                 .when(df.gender.isNull() ,\"\")\n",
        "                                 .otherwise(df.gender))\n",
        "df.show()"
      ],
      "metadata": {
        "id": "rNk2gWJhJAbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import expr, col\n",
        "\n",
        "#Using Case When on withColumn()\n",
        "df3 = df.withColumn(\"new_gender\", expr(\"CASE WHEN gender = 'M' THEN 'Male' \" + \n",
        "               \"WHEN gender = 'F' THEN 'Female' WHEN gender IS NULL THEN ''\" +\n",
        "               \"ELSE gender END\"))\n",
        "df3.show(truncate=False)"
      ],
      "metadata": {
        "id": "yd5nc_K-JcrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.createOrReplaceTempView(\"EMP\")\n",
        "spark.sql(\"select name, CASE WHEN gender = 'M' THEN 'Male' \" + \n",
        "               \"WHEN gender = 'F' THEN 'Female' WHEN gender IS NULL THEN ''\" +\n",
        "              \"ELSE gender END as new_gender from EMP\").show()"
      ],
      "metadata": {
        "id": "xQKHWAGsJjca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data =[(\"James \",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
        "              (\"Michael \",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
        "              (\"Robert \",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
        "              (\"Maria \",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
        "              (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)]\n",
        "columns=[\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
        "df=spark.createDataFrame(data,columns)\n",
        "df.write.mode(\"overwrite\").parquet(\"people.parquet\")\n",
        "parDF1=spark.read.parquet(\"people.parquet\")\n",
        "parDF1.createOrReplaceTempView(\"parquetTable\")\n",
        "parDF1.printSchema()\n",
        "parDF1.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HJOnYAGKGwr",
        "outputId": "d9d4f4cb-5740-4b8d-a830-b71a1ab58273"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            " |-- dob: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n",
            "+---------+----------+--------+-----+------+------+\n",
            "|firstname|middlename|lastname|dob  |gender|salary|\n",
            "+---------+----------+--------+-----+------+------+\n",
            "|James    |          |Smith   |36636|M     |3000  |\n",
            "|Michael  |Rose      |        |40288|M     |4000  |\n",
            "|Robert   |          |Williams|42114|M     |4000  |\n",
            "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
            "|Jen      |Mary      |Brown   |     |F     |-1    |\n",
            "+---------+----------+--------+-----+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "parkSQL = spark.sql(\"select * from ParquetTable where salary >= 4000 \")\n",
        "parkSQL.show(truncate=False)\n",
        "\n",
        "\n",
        "df.write.partitionBy(\"gender\",\"salary\").mode(\"overwrite\").parquet(\"people.parquet\")\n",
        "\n",
        "parDF2=spark.read.parquet(\"people.parquet/gender=M\")\n",
        "parDF2.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22mpodbrVnEU",
        "outputId": "c70004eb-4750-402d-be64-22e4520e8991"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+-----+------+------+\n",
            "|firstname|middlename|lastname|dob  |gender|salary|\n",
            "+---------+----------+--------+-----+------+------+\n",
            "|Michael  |Rose      |        |40288|M     |4000  |\n",
            "|Robert   |          |Williams|42114|M     |4000  |\n",
            "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
            "+---------+----------+--------+-----+------+------+\n",
            "\n",
            "+---------+----------+--------+-----+------+\n",
            "|firstname|middlename|lastname|dob  |salary|\n",
            "+---------+----------+--------+-----+------+\n",
            "|James    |          |Smith   |36636|3000  |\n",
            "|Michael  |Rose      |        |40288|4000  |\n",
            "|Robert   |          |Williams|42114|4000  |\n",
            "+---------+----------+--------+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.json(\"flights_sample.json\")\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIb6ougxWgJW",
        "outputId": "7ac72569-5815-4703-f737-2ce2ae5e2d2d"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- ARR_DELAY: long (nullable = true)\n",
            " |-- ARR_TIME: string (nullable = true)\n",
            " |-- CANCELLED: boolean (nullable = true)\n",
            " |-- CRS_ARR_TIME: string (nullable = true)\n",
            " |-- CRS_DEP_TIME: string (nullable = true)\n",
            " |-- DEP_DELAY: long (nullable = true)\n",
            " |-- DEP_TIME: string (nullable = true)\n",
            " |-- DEST: string (nullable = true)\n",
            " |-- DEST_AIRPORT_SEQ_ID: string (nullable = true)\n",
            " |-- DISTANCE: string (nullable = true)\n",
            " |-- DIVERTED: boolean (nullable = true)\n",
            " |-- FL_DATE: string (nullable = true)\n",
            " |-- ORIGIN: string (nullable = true)\n",
            " |-- ORIGIN_AIRPORT_SEQ_ID: string (nullable = true)\n",
            " |-- TAXI_IN: long (nullable = true)\n",
            " |-- TAXI_OUT: long (nullable = true)\n",
            " |-- UNIQUE_CARRIER: string (nullable = true)\n",
            " |-- WHEELS_OFF: string (nullable = true)\n",
            " |-- WHEELS_ON: string (nullable = true)\n",
            "\n",
            "+---------+--------+---------+------------+------------+---------+--------+----+-------------------+--------+--------+----------+------+---------------------+-------+--------+--------------+----------+---------+\n",
            "|ARR_DELAY|ARR_TIME|CANCELLED|CRS_ARR_TIME|CRS_DEP_TIME|DEP_DELAY|DEP_TIME|DEST|DEST_AIRPORT_SEQ_ID|DISTANCE|DIVERTED|   FL_DATE|ORIGIN|ORIGIN_AIRPORT_SEQ_ID|TAXI_IN|TAXI_OUT|UNIQUE_CARRIER|WHEELS_OFF|WHEELS_ON|\n",
            "+---------+--------+---------+------------+------------+---------+--------+----+-------------------+--------+--------+----------+------+---------------------+-------+--------+--------------+----------+---------+\n",
            "|      -18|    1751|    false|        1809|        1600|       -5|    1555| ATL|            1000101|  692.00|   false|2015-04-28|   ABE|              1000101|      4|       7|            EV|      1602|     1747|\n",
            "|      -19|    0759|    false|        0818|        0600|       -4|    0556| ATL|            1000101|  692.00|   false|2015-11-05|   ABE|              1000101|     10|      12|            DL|      0608|     0749|\n",
            "+---------+--------+---------+------------+------------+---------+--------+----+-------------------+--------+--------+----------+------+---------------------+-------+--------+--------------+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "columns = [\"id\", \"name\",\"age\",\"gender\"]\n",
        "\n",
        "# Create DataFrame \n",
        "data = [(1, \"James\",30,\"M\"), (2, \"Ann\",40,\"F\"),\n",
        "    (3, \"Jeff\",41,\"M\"),(4, \"Jennifer\",20,\"F\")]\n",
        "sampleDF = spark.sparkContext.parallelize(data).toDF(columns)\n",
        "\n",
        "# Create Hive Internal table\n",
        "sampleDF.write.mode('overwrite') \\\n",
        "         .saveAsTable(\"employee\")\n",
        "\n",
        "# Read Hive table\n",
        "df = spark.read.table(\"employee\")\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqzzX0FAXDy0",
        "outputId": "f33176ab-d6c4-42a0-ed74-5e7e5cf634e6"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+---+------+\n",
            "| id|    name|age|gender|\n",
            "+---+--------+---+------+\n",
            "|  1|   James| 30|     M|\n",
            "|  2|     Ann| 40|     F|\n",
            "|  3|    Jeff| 41|     M|\n",
            "|  4|Jennifer| 20|     F|\n",
            "+---+--------+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "simpleData = ((\"James\", \"Sales\", 10), \\\n",
        "    (\"Robert\", \"Sales\", 20),   \\\n",
        "    (\"Maria\", \"Finance\", 40),  \\\n",
        "    (\"Saif\", \"Sales\", 30), \\\n",
        "    (\"Saif\", \"Sales\", 30), \\\n",
        "    (\"ali\", \"Sales\", 50) \\\n",
        "  )\n",
        " \n",
        "columns= [\"employee_name\", \"department\", \"salary\"]\n",
        "df = spark.createDataFrame(data = simpleData, schema = columns)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A31EqhohXl14",
        "outputId": "c81d49b3-a7ff-4986-b332-db995cf46e5e"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- employee_name: string (nullable = true)\n",
            " |-- department: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n",
            "+-------------+----------+------+\n",
            "|employee_name|department|salary|\n",
            "+-------------+----------+------+\n",
            "|James        |Sales     |10    |\n",
            "|Robert       |Sales     |20    |\n",
            "|Maria        |Finance   |40    |\n",
            "|Saif         |Sales     |30    |\n",
            "|Saif         |Sales     |30    |\n",
            "|ali          |Sales     |50    |\n",
            "+-------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col,avg,sum,min,max,row_number \n",
        "\n",
        "windowSpec  = Window.partitionBy(\"department\").orderBy(\"salary\")\n",
        "\n",
        "df=df.withColumn(\"row_number\",row_number().over(windowSpec)) \n",
        "df=df.withColumn(\"rank\",rank().over(windowSpec))\n",
        "df=df.withColumn(\"dense_rank\",dense_rank().over(windowSpec))\n",
        "df=df.withColumn(\"lead\",lead(\"salary\",2).over(windowSpec))\n",
        "df.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNpcCMsMXpsO",
        "outputId": "3f36eeac-aa85-4bb5-a45c-5a69678ef638"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+----------+----+----------+----+\n",
            "|employee_name|department|salary|row_number|rank|dense_rank|lead|\n",
            "+-------------+----------+------+----------+----+----------+----+\n",
            "|Maria        |Finance   |40    |1         |1   |1         |null|\n",
            "|James        |Sales     |10    |1         |1   |1         |30  |\n",
            "|Robert       |Sales     |20    |2         |2   |2         |30  |\n",
            "|Saif         |Sales     |30    |3         |3   |3         |50  |\n",
            "|Saif         |Sales     |30    |4         |3   |3         |null|\n",
            "|ali          |Sales     |50    |5         |5   |4         |null|\n",
            "+-------------+----------+------+----------+----+----------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dept\n",
        "  salary\n",
        "  \n",
        "    Finance \n",
        "    40\n",
        "\n",
        "    sales\n",
        "    10\n",
        "    20\n",
        "    30\n",
        "    30"
      ],
      "metadata": {
        "id": "GbVRDGwGZAs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df2=df.withColumn(\"row\",row_number().over(windowSpec)).withColumn(\"avg\", avg(col(\"salary\")).over(windowSpec)) \n",
        "df2=df2.withColumn(\"sum\", sum(col(\"salary\")).over(windowSpec)) \n",
        "df2=df2.withColumn(\"min\", min(col(\"salary\")).over(windowSpec)) \n",
        "df2=df2.withColumn(\"max\", max(col(\"salary\")).over(windowSpec)) \n",
        "df2=df2.where(col(\"row\")==1).select(\"department\",\"avg\",\"sum\",\"min\",\"max\")\n",
        "df2.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRYzHdAFaqY-",
        "outputId": "e1f9a50b-c277-4728-ce20-b4b37e260905"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+---+---+---+\n",
            "|department|avg |sum|min|max|\n",
            "+----------+----+---+---+---+\n",
            "|Finance   |40.0|40 |40 |40 |\n",
            "|Sales     |10.0|10 |10 |10 |\n",
            "+----------+----+---+---+---+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}